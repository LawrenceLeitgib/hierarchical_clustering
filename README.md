# Non-Binary Hierarchical Clustering

This project performs Non-Binary hierarchical clustering on arXiv and Wikipedia dataset.

---

## ğŸ”§ Setup Instructions

### 1. Prepare the Dataset
Download and add the following dataset to the `resources/` folder:

- **File:** `arxiv-metadata-oai-snapshot.json`  
- **Source:** [Kaggle - Cornell University arXiv Dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv)

---

## ğŸ§ª Compute Similarity Matrix

Different scripts are provided depending on the type of data you want to cluster:

### ğŸ“„ Paper-to-Paper Similarity
Run `compute_paper_to_paper_similarity.py` with the following arguments:

```bash
--embedding     # Embedding type (default: 'TF-IDF')
--num_samples   # Number of samples to use (default: 200)
--metric        # Clustering metric (default: 'cosine')
--PCA           # Apply PCA (flag)
--g             # Plot PCA explained variance (flag)
--MC            # Max number of categories (default: 6)
--balance       # Category balance factor (default: 0.1)
```

### ğŸ“š Subcategory-to-Subcategory Similarity
Run `compute_subcat_to_subcat_similarity.py` with:

```bash
--embedding     # Embedding type (default: 'TF-IDF')
--num_samples   # Number of samples to use (default: 1000)
--metric        # Clustering metric (default: 'cosine')
--PCA           # Apply PCA (flag)
--g             # Plot PCA explained variance (flag)
--MC            # Max number of categories
--balance       # Category balance factor (default: 0.1)
```

### ğŸŒ Wikipedia Similarity (Abstracts and Adjacency)
Run `compute_wikipedia_similarity.py`:

```bash
--embedding     # Embedding type (default: 'TF-IDF')
--num_samples   # Number of samples to use (default: 200)
--metric        # Clustering metric (default: 'cosine')
--PCA           # Apply PCA (for the abstract matrix) (flag)
--g             # Plot PCA explained variance (flag)
```

---

## ğŸ§© Run Hierarchical Clustering

Use `main.py` after computing the similarity matrix:

```bash
--embedding     # Embedding type (default: 'TF-IDF')
--num_samples   # Number of samples to use (default: 100)
--metric        # Linkage metric (same as for similarity)
--eps           # Epsilon value for Algorithm 3
--delta         # Delta value for Algorithm 3 (default: 0.1)
--deltaType     # Type of delta algorithm (default: 2)
--PCA           # Apply PCA (flag)
--dataset       # Dataset: 'wikipedia', 'categories', or 'abstracts'
--lead          # if the flag is use it will cluster on abstract else it will cluster on the adjency matrix
```

---

## ğŸ“ Project Structure

```
hierarchical_clustering/
â”‚
â”œâ”€â”€ resources/                        # Dataset location
â”‚   â””â”€â”€ arxiv-metadata-oai-snapshot.json
â”œâ”€â”€ compute_paper_to_paper_similarity.py
â”œâ”€â”€ compute_subcat_to_subcat_similarity.py
â”œâ”€â”€ compute_wikipedia_similarity.py
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
```

---

## ğŸ“Œ Notes

-- To enable GPU compatibility, modify main.py as mention in the comments

---

## ğŸ“œ License

This project is licensed under the MIT License.
